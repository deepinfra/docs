---
title: Data Privacy
description: How DeepInfra handles your data during inference — what's stored, what's not.
icon: shield
---

This page explains how DeepInfra handles data when you use our inference APIs.

## Summary

- **Input data is not stored to disk** during inference — it exists only in memory while the request is being processed
- **Output data is not stored** — it is sent to you and then deleted from memory
- **We do not train on your data** (except Google/Anthropic model exceptions below)
- **We do not share your data with third parties** (except Google/Anthropic model exceptions below)

## Data privacy

When using DeepInfra inference APIs, we do not store the data you submit to our APIs on disk. We only hold it in memory during the inference process. Once inference is complete, the data is deleted from memory.

The same applies to outputs — once sent back to you, they are deleted.

**Exception:** Outputs of image generation models are stored for a short period of time to allow easy access (e.g., for the model demo page).

### Google models

If you opt to use a Google model, Google will store the output as outlined in their [Privacy Notice](https://cloud.google.com/terms/cloud-privacy-notice).

### Anthropic models

If you opt to use an Anthropic model, Anthropic will store the output as outlined in their [Trust Center](https://trust.anthropic.com/).

## Bulk inference APIs

When using our bulk inference APIs (submitting multiple requests in a single call), we may need to store data for a longer period, potentially on disk in encrypted form. Once inference is complete and results are returned to you, the data is deleted from disk and memory after a short retention period.

## No training

We do not use data you submit to our APIs for training models, except when using Google or Anthropic models, where the receiving company's training policy applies.

## No sharing

We do not share data you submit to our APIs with any third party, except when using Google or Anthropic models, where we are required to transfer data to those endpoints to fulfill the request.

## Logs

We generally do not log the content of your requests. We log metadata useful for debugging: request ID, cost, sampling parameters. We reserve the right to log a small portion of requests when necessary for debugging or security purposes.

When using the Google model, Google logs prompts and responses for a limited period solely to detect violations of their [Prohibited Use Policy](https://policies.google.com/terms/generative-ai/use-policy).

## Personal information

Personal information and data provided when using certain models through our API may be shared with the relevant model API endpoints, as specified at the time of use.
