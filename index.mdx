---
title: What is DeepInfra
description: AI inference cloud — OpenAI-compatible API, 100s of open-source models, private GPU deployments, and GPU rental.
icon: bolt
---

DeepInfra is an AI inference cloud that makes it simple to run the latest machine learning models at scale.

## What you can do

<CardGroup cols={2}>
  <Card title="Chat Completions" icon="comments" href="/chat/overview">
    OpenAI-compatible API. Swap your base URL, keep your code.
  </Card>
  <Card title="100+ Models" icon="brain" href="/models">
    Llama, DeepSeek, Mistral, Qwen, FLUX, Whisper, and more — always up to date.
  </Card>
  <Card title="Deploy Private Models" icon="lock" href="/private-models/overview">
    Run your own LLM on A100 / H100 / H200 / B200 GPUs with autoscaling.
  </Card>
  <Card title="GPU Instances" icon="server" href="/gpu-instances/overview">
    Rent bare-metal GPU instances (B200, H200, and more) with SSH access.
  </Card>
</CardGroup>

## Why DeepInfra

**Drop-in OpenAI replacement.** Point your existing OpenAI SDK to `https://api.deepinfra.com/v1/openai` and your code works without changes. No migration required.

**Best price for open-source models.** DeepInfra consistently offers the lowest prices for open-source model inference. You only pay per token — no idle GPU time, no minimums, no seat fees. DeepInfra is also the provider with the most models on [OpenRouter](https://openrouter.ai).

**Always-fresh model catalog.** DeepInfra is typically among the first providers to deploy a newly released model.

**Private deployments for compliance and customization.** Need to run your own fine-tuned weights, or require data isolation? Deploy a dedicated instance on A100/H100/H200/B200 with autoscaling and a private endpoint.

**GPU rental for training and experimentation.** Need full control? Rent a B200 or H200 instance with SSH access and run whatever you want.

## Get started in 60 seconds

<Card title="Quickstart" icon="play" href="/quickstart">
  Make your first API call — no installation required.
</Card>

## Quick example

```python
from openai import OpenAI

client = OpenAI(
    api_key="$DEEPINFRA_TOKEN",
    base_url="https://api.deepinfra.com/v1/openai",
)

response = client.chat.completions.create(
    model="deepseek-ai/DeepSeek-V3",
    messages=[{"role": "user", "content": "Hello!"}],
)
print(response.choices[0].message.content)
```

Get your API key from the [Dashboard](https://deepinfra.com/dash/api_keys).
